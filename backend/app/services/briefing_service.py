"""
ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„± ë° ë°œì†¡ ì„œë¹„ìŠ¤
"""
import os
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from sqlalchemy.orm import Session
from sqlalchemy import func, and_

from app.models.complex import Complex, ArticleChange
from app.services.article_tracker import ArticleTracker
from app.integrations.notifications import NotificationManager

logger = logging.getLogger(__name__)


class BriefingService:
    """ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„± ë° ë°œì†¡ ì„œë¹„ìŠ¤"""

    def __init__(self, db: Session):
        self.db = db
        self.tracker = ArticleTracker(db)
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ Webhook URL ì½ê¸°
        slack_webhook = os.getenv('SLACK_WEBHOOK_URL')
        discord_webhook = os.getenv('DISCORD_WEBHOOK_URL')
        self.notification_manager = NotificationManager(
            slack_webhook=slack_webhook,
            discord_webhook=discord_webhook
        )

    def generate_weekly_briefing(
        self,
        days: int = 7,
        mark_as_read: bool = True
    ) -> Dict:
        """
        ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„±

        Args:
            days: ì¡°íšŒí•  ì¼ìˆ˜ (ê¸°ë³¸: 7ì¼)
            mark_as_read: ìƒì„± í›„ ë³€ë™ì‚¬í•­ì„ ì½ìŒìœ¼ë¡œ í‘œì‹œí• ì§€ ì—¬ë¶€

        Returns:
            ë¸Œë¦¬í•‘ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        logger.info(f"ğŸ“Š ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„± ì‹œì‘ (ì§€ë‚œ {days}ì¼)")

        since = datetime.now() - timedelta(days=days)
        end_date = datetime.now()

        # ëª¨ë“  ë“±ë¡ëœ ë‹¨ì§€ ì¡°íšŒ
        complexes = self.db.query(Complex).all()

        if not complexes:
            logger.warning("ë“±ë¡ëœ ë‹¨ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {
                'period': {'start': since, 'end': end_date, 'days': days},
                'complexes': [],
                'total_summary': self._get_empty_summary(),
                'markdown': self._generate_empty_briefing_markdown(since, end_date)
            }

        # ì „ì²´ ë³€ë™ì‚¬í•­ ì¡°íšŒ
        all_changes = (
            self.db.query(ArticleChange)
            .filter(
                ArticleChange.detected_at >= since,
                ArticleChange.is_read == False  # ì½ì§€ ì•Šì€ ë³€ë™ì‚¬í•­ë§Œ
            )
            .all()
        )

        # ë‹¨ì§€ë³„ ë³€ë™ì‚¬í•­ ì§‘ê³„
        complex_data = []
        total_summary = {
            'new': 0,
            'removed': 0,
            'price_up': 0,
            'price_down': 0,
            'total': 0
        }

        for complex_obj in complexes:
            complex_id = complex_obj.complex_id

            # í•´ë‹¹ ë‹¨ì§€ì˜ ë³€ë™ì‚¬í•­ í•„í„°ë§
            complex_changes = [c for c in all_changes if c.complex_id == complex_id]

            if not complex_changes:
                continue  # ë³€ë™ì‚¬í•­ì´ ì—†ëŠ” ë‹¨ì§€ëŠ” ê±´ë„ˆë›°ê¸°

            # ë³€ë™ì‚¬í•­ ë¶„ë¥˜
            new_count = len([c for c in complex_changes if c.change_type == 'NEW'])
            removed_count = len([c for c in complex_changes if c.change_type == 'REMOVED'])
            price_up_count = len([c for c in complex_changes if c.change_type == 'PRICE_UP'])
            price_down_count = len([c for c in complex_changes if c.change_type == 'PRICE_DOWN'])

            # ê°€ì¥ í° ê°€ê²© ë³€ë™ ì°¾ê¸°
            price_changes = [c for c in complex_changes if c.change_type in ['PRICE_UP', 'PRICE_DOWN']]
            most_significant_change = None
            if price_changes:
                most_significant_change = max(
                    price_changes,
                    key=lambda c: abs(c.price_change_percent) if c.price_change_percent else 0
                )

            summary = {
                'new': new_count,
                'removed': removed_count,
                'price_up': price_up_count,
                'price_down': price_down_count,
                'total': len(complex_changes),
                'most_significant_change': most_significant_change
            }

            complex_data.append({
                'complex': complex_obj,
                'summary': summary,
                'changes': complex_changes
            })

            # ì „ì²´ ìš”ì•½ì— í•©ì‚°
            total_summary['new'] += new_count
            total_summary['removed'] += removed_count
            total_summary['price_up'] += price_up_count
            total_summary['price_down'] += price_down_count
            total_summary['total'] += len(complex_changes)

        # ë§ˆí¬ë‹¤ìš´ ìƒì„±
        markdown = self._generate_briefing_markdown(
            since,
            end_date,
            complex_data,
            total_summary
        )

        # ì½ìŒ ì²˜ë¦¬
        if mark_as_read and all_changes:
            for change in all_changes:
                change.is_read = True
            self.db.commit()
            logger.info(f"âœ… {len(all_changes)}ê±´ì˜ ë³€ë™ì‚¬í•­ì„ ì½ìŒìœ¼ë¡œ í‘œì‹œ")

        briefing_data = {
            'period': {
                'start': since,
                'end': end_date,
                'days': days
            },
            'complexes': complex_data,
            'total_summary': total_summary,
            'markdown': markdown
        }

        logger.info(f"âœ… ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„± ì™„ë£Œ (ì´ {len(complex_data)}ê°œ ë‹¨ì§€, {total_summary['total']}ê±´ ë³€ë™)")
        return briefing_data

    def send_briefing(
        self,
        days: int = 7,
        to_slack: bool = True,
        to_discord: bool = True,
        crawl_stats: Dict = None
    ) -> Dict:
        """
        ì£¼ê°„ ë¸Œë¦¬í•‘ ìƒì„± ë° ë°œì†¡

        Args:
            days: ì¡°íšŒí•  ì¼ìˆ˜
            to_slack: Slack ì „ì†¡ ì—¬ë¶€
            to_discord: Discord ì „ì†¡ ì—¬ë¶€
            crawl_stats: í¬ë¡¤ë§ í†µê³„ (ì„ íƒì‚¬í•­)

        Returns:
            ë°œì†¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ë¸Œë¦¬í•‘ ìƒì„±
        briefing = self.generate_weekly_briefing(days=days, mark_as_read=True)

        # í¬ë¡¤ë§ í†µê³„ ì¶”ê°€
        if crawl_stats:
            briefing['crawl_stats'] = crawl_stats

        # ì•Œë¦¼ ì±„ë„ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
        if not self.notification_manager.is_configured():
            logger.error("âŒ ì•Œë¦¼ ì±„ë„ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return {
                'success': False,
                'error': 'No notification channels configured',
                'briefing': briefing
            }

        # ë³€ë™ì‚¬í•­ì´ ì—†ëŠ” ê²½ìš°
        if briefing['total_summary']['total'] == 0:
            # í¬ë¡¤ë§ í†µê³„ê°€ ìˆìœ¼ë©´ "ë³€ë™ì‚¬í•­ ì—†ìŒ" ë©”ì‹œì§€ë¡œ ë¸Œë¦¬í•‘ ì „ì†¡
            if not crawl_stats:
                logger.info("â„¹ï¸  ë³€ë™ì‚¬í•­ì´ ì—†ì–´ ì•Œë¦¼ì„ ì „ì†¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return {
                    'success': True,
                    'skipped': True,
                    'reason': 'No changes to report',
                    'briefing': briefing
                }
            # í¬ë¡¤ë§ í†µê³„ê°€ ìˆìœ¼ë©´ ê³„ì† ì§„í–‰í•˜ì—¬ "ë³€ë™ì‚¬í•­ ì—†ìŒ" ë¸Œë¦¬í•‘ ì „ì†¡
            logger.info("â„¹ï¸  ë³€ë™ì‚¬í•­ì€ ì—†ì§€ë§Œ í¬ë¡¤ë§ í†µê³„ ë¸Œë¦¬í•‘ì„ ì „ì†¡í•©ë‹ˆë‹¤.")

        # ì•Œë¦¼ ë°œì†¡
        markdown = briefing['markdown']

        # í¬ë¡¤ë§ í†µê³„ê°€ ìˆìœ¼ë©´ ë§ˆí¬ë‹¤ìš´ì— ì¶”ê°€
        if crawl_stats:
            crawl_summary = self._generate_crawl_summary_markdown(crawl_stats)
            markdown = crawl_summary + "\n\n" + markdown

        results = {}

        if to_slack and self.notification_manager.slack.webhook_url:
            logger.info("ğŸ“¤ Slackìœ¼ë¡œ ë¸Œë¦¬í•‘ ì „ì†¡ ì¤‘...")
            results['slack'] = self.notification_manager.slack.send_markdown(markdown)

        if to_discord and self.notification_manager.discord.webhook_url:
            logger.info("ğŸ“¤ Discordë¡œ ë¸Œë¦¬í•‘ ì „ì†¡ ì¤‘...")
            results['discord'] = self.notification_manager.discord.send_markdown(markdown)

        success = any(results.values())

        if success:
            logger.info(f"âœ… ë¸Œë¦¬í•‘ ì „ì†¡ ì™„ë£Œ: {results}")
        else:
            logger.error(f"âŒ ë¸Œë¦¬í•‘ ì „ì†¡ ì‹¤íŒ¨: {results}")

        return {
            'success': success,
            'results': results,
            'briefing': briefing
        }

    def _generate_briefing_markdown(
        self,
        start_date: datetime,
        end_date: datetime,
        complex_data: List[Dict],
        total_summary: Dict
    ) -> str:
        """
        ë¸Œë¦¬í•‘ ë§ˆí¬ë‹¤ìš´ ìƒì„±

        Args:
            start_date: ì‹œì‘ì¼
            end_date: ì¢…ë£Œì¼
            complex_data: ë‹¨ì§€ë³„ ë°ì´í„°
            total_summary: ì „ì²´ ìš”ì•½

        Returns:
            ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
        """
        lines = []

        # í—¤ë”
        lines.append("# ğŸ  ì£¼ê°„ ë¶€ë™ì‚° ë¸Œë¦¬í•‘")
        lines.append("")
        lines.append(f"ğŸ“… **ê¸°ê°„**: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
        lines.append("")

        # ì „ì²´ ìš”ì•½
        lines.append("## ğŸ“Š ì „ì²´ ìš”ì•½")
        lines.append(f"- ì´ ë‹¨ì§€ ìˆ˜: **{len(complex_data)}ê°œ**")
        lines.append(f"- ì‹ ê·œ ë§¤ë¬¼: **{total_summary['new']}ê±´** ğŸ†•")
        lines.append(f"- ì‚­ì œ ë§¤ë¬¼: **{total_summary['removed']}ê±´** âŒ")
        lines.append(f"- ê°€ê²© ë³€ë™: **{total_summary['price_up'] + total_summary['price_down']}ê±´** (â†‘{total_summary['price_up']}ê±´, â†“{total_summary['price_down']}ê±´)")
        lines.append("")
        lines.append("---")
        lines.append("")

        # ë‹¨ì§€ë³„ ìƒì„¸
        lines.append("## ğŸ¢ ë‹¨ì§€ë³„ ìƒì„¸ ì •ë³´")
        lines.append("")

        for data in complex_data:
            complex_obj = data['complex']
            summary = data['summary']
            most_sig = summary.get('most_significant_change')

            lines.append(f"### {complex_obj.complex_name}")
            lines.append(f"- **ì‹ ê·œ ë§¤ë¬¼**: {summary['new']}ê±´")
            lines.append(f"- **ì‚­ì œ ë§¤ë¬¼**: {summary['removed']}ê±´")
            lines.append(f"- **ê°€ê²© ìƒìŠ¹**: {summary['price_up']}ê±´")
            lines.append(f"- **ê°€ê²© í•˜ë½**: {summary['price_down']}ê±´")

            # ê°€ì¥ í° ë³€ë™ í•˜ì´ë¼ì´íŠ¸
            if most_sig:
                change_icon = "ğŸ“ˆ" if most_sig.change_type == 'PRICE_UP' else "ğŸ“‰"
                lines.append(f"- {change_icon} **ì£¼ëª©**: {most_sig.area_name or ''} {most_sig.trade_type or ''} "
                           f"{most_sig.old_price} â†’ {most_sig.new_price} "
                           f"({most_sig.price_change_percent:+.1f}%)")

            lines.append("")

        # í‘¸í„°
        lines.append("---")
        lines.append("")
        next_briefing = end_date + timedelta(days=7)
        lines.append(f"â° **ë‹¤ìŒ ë¸Œë¦¬í•‘**: {next_briefing.strftime('%Y-%m-%d (%a)')}")
        lines.append("")
        lines.append("_ì´ ë¸Œë¦¬í•‘ì€ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤._")

        return "\n".join(lines)

    def _generate_empty_briefing_markdown(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> str:
        """ë³€ë™ì‚¬í•­ì´ ì—†ì„ ë•Œì˜ ë¸Œë¦¬í•‘"""
        lines = []
        lines.append("# ğŸ  ì£¼ê°„ ë¶€ë™ì‚° ë¸Œë¦¬í•‘")
        lines.append("")
        lines.append(f"ğŸ“… **ê¸°ê°„**: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
        lines.append("")
        lines.append("## âœ… ë³€ë™ì‚¬í•­ ì—†ìŒ")
        lines.append("")
        lines.append("âœ¨ ì§€ë‚œ ì£¼ê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ë‹¨ì§€ì˜ ë§¤ë¬¼ ê°€ê²© ë° ë§¤ë¬¼ ìˆ˜ì— ë³€ë™ì´ ì—†ìŠµë‹ˆë‹¤.")
        lines.append("")
        lines.append("- ì‹ ê·œ ë§¤ë¬¼: ì—†ìŒ")
        lines.append("- ì‚­ì œëœ ë§¤ë¬¼: ì—†ìŒ")
        lines.append("- ê°€ê²© ë³€ë™: ì—†ìŒ")
        lines.append("")
        lines.append("ğŸ’¡ ì‹œì¥ì´ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        lines.append("")
        lines.append("---")
        lines.append("")
        next_briefing = end_date + timedelta(days=7)
        lines.append(f"â° **ë‹¤ìŒ ë¸Œë¦¬í•‘**: {next_briefing.strftime('%Y-%m-%d (%a)')}")

        return "\n".join(lines)

    @staticmethod
    def _get_empty_summary() -> Dict:
        """ë¹ˆ ìš”ì•½ ë°ì´í„°"""
        return {
            'new': 0,
            'removed': 0,
            'price_up': 0,
            'price_down': 0,
            'total': 0
        }

    @staticmethod
    def _generate_crawl_summary_markdown(crawl_stats: Dict) -> str:
        """
        í¬ë¡¤ë§ í†µê³„ ìš”ì•½ ë§ˆí¬ë‹¤ìš´ ìƒì„±

        Args:
            crawl_stats: í¬ë¡¤ë§ í†µê³„ ë”•ì…”ë„ˆë¦¬

        Returns:
            ë§ˆí¬ë‹¤ìš´ ë¬¸ìì—´
        """
        lines = []
        lines.append("# ğŸ¤– ìë™ í¬ë¡¤ë§ ì™„ë£Œ")
        lines.append("")

        # ì‹œì‘/ì¢…ë£Œ ì‹œê°„
        started_at = crawl_stats.get('started_at', '')
        finished_at = crawl_stats.get('finished_at', '')
        if started_at and finished_at:
            from datetime import datetime
            start_dt = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
            finish_dt = datetime.fromisoformat(finished_at.replace('Z', '+00:00'))
            lines.append(f"â° **ì‹œì‘**: {start_dt.strftime('%Y-%m-%d %H:%M:%S')}")
            lines.append(f"â° **ì™„ë£Œ**: {finish_dt.strftime('%Y-%m-%d %H:%M:%S')}")
            duration = crawl_stats.get('duration_seconds', 0)
            lines.append(f"â±ï¸ **ì†Œìš”ì‹œê°„**: {duration}ì´ˆ ({duration // 60}ë¶„ {duration % 60}ì´ˆ)")
            lines.append("")

        # í¬ë¡¤ë§ ê²°ê³¼
        lines.append("## ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼")
        lines.append(f"- ëŒ€ìƒ ë‹¨ì§€: **{crawl_stats.get('total_complexes', 0)}ê°œ**")
        lines.append(f"- ì„±ê³µ: **{crawl_stats.get('success', 0)}ê°œ** âœ…")
        lines.append(f"- ì‹¤íŒ¨: **{crawl_stats.get('failed', 0)}ê°œ** âŒ")
        lines.append(f"- ìˆ˜ì§‘ ë§¤ë¬¼: **{crawl_stats.get('total_articles_collected', 0)}ê±´**")
        lines.append(f"- ì‹ ê·œ ë§¤ë¬¼: **{crawl_stats.get('total_articles_new', 0)}ê±´** ğŸ†•")

        # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        errors = crawl_stats.get('errors', [])
        if errors:
            lines.append("")
            lines.append("### âš ï¸ ì˜¤ë¥˜ ë°œìƒ")
            for error in errors[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                lines.append(f"- {error}")

        lines.append("")
        lines.append("---")

        return "\n".join(lines)
