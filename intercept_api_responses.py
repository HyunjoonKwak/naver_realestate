"""
ë„¤íŠ¸ì›Œí¬ ì‘ë‹µ ê°€ë¡œì±„ê¸°
ë„¤ì´ë²„ ë¶€ë™ì‚° API ì‘ë‹µ ë°ì´í„°ë¥¼ ì§ì ‘ ìº¡ì²˜
"""
import asyncio
import json
from playwright.async_api import async_playwright


async def intercept_and_extract():
    """ë„¤íŠ¸ì›Œí¬ ì‘ë‹µì„ ê°€ë¡œì±„ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ"""

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        print("=" * 80)
        print("ğŸ•µï¸  ë„¤ì´ë²„ ë¶€ë™ì‚° API ì‘ë‹µ ê°€ë¡œì±„ê¸°")
        print("=" * 80)

        captured_data = {
            'complexes': [],
            'complex_detail': None,
            'listings': [],
            'transactions': []
        }

        # ì‘ë‹µ ê°€ë¡œì±„ê¸°
        async def handle_response(response):
            """API ì‘ë‹µ ìº¡ì²˜"""
            url = response.url

            # ë‹¨ì§€ ëª©ë¡ API
            if '/api/complexes' in url or '/api/search' in url:
                try:
                    if response.status == 200:
                        data = await response.json()
                        print(f"\nâœ… API ì‘ë‹µ ìº¡ì²˜: {url}")
                        print(f"   ì‘ë‹µ í¬ê¸°: {len(str(data))} bytes")

                        # íŒŒì¼ë¡œ ì €ì¥
                        filename = None
                        if 'single-markers' in url:
                            filename = 'api_complexes_markers.json'
                            captured_data['complexes'] = data
                        elif 'complexes/' in url and url.split('/')[-1].isdigit():
                            filename = 'api_complex_detail.json'
                            captured_data['complex_detail'] = data
                        elif 'articles' in url or 'listings' in url:
                            filename = 'api_listings.json'
                            captured_data['listings'] = data
                        elif 'trade' in url or 'transaction' in url:
                            filename = 'api_transactions.json'
                            captured_data['transactions'] = data
                        else:
                            filename = f'api_response_{len(captured_data["complexes"])}.json'

                        if filename:
                            with open(filename, 'w', encoding='utf-8') as f:
                                json.dump(data, f, ensure_ascii=False, indent=2)
                            print(f"   ğŸ’¾ ì €ì¥ë¨: {filename}")

                            # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                            preview = json.dumps(data, ensure_ascii=False, indent=2)[:500]
                            print(f"   ğŸ“„ ë¯¸ë¦¬ë³´ê¸°:\n{preview}...")

                except Exception as e:
                    print(f"âš ï¸  ì‘ë‹µ íŒŒì‹± ì—ëŸ¬ ({url}): {e}")

        page.on("response", handle_response)

        # 1. ë©”ì¸ í˜ì´ì§€ ì ‘ì† (ì„œìš¸ ê°•ë‚¨ ì§€ì—­)
        print("\n1ï¸âƒ£  ë©”ì¸ í˜ì´ì§€ ì ‘ì†...")
        url = "https://new.land.naver.com/complexes?ms=37.498095,127.027610,16&a=APT&e=RETAIL"
        await page.goto(url, wait_until="networkidle")
        await asyncio.sleep(5)

        # 2. ì§€ë„ ì´ë™í•´ì„œ ë” ë§ì€ ë‹¨ì§€ ë¡œë“œ
        print("\n2ï¸âƒ£  ì§€ë„ ì´ë™ (ë” ë§ì€ ë‹¨ì§€ ë¡œë“œ)...")
        await page.evaluate('''
            () => {
                // í˜ì´ì§€ë¥¼ ì¡°ê¸ˆì”© ìŠ¤í¬ë¡¤í•˜ì—¬ ë” ë§ì€ ë°ì´í„° ë¡œë“œ
                window.scrollBy(0, 300);
            }
        ''')
        await asyncio.sleep(3)

        # 3. ê²€ìƒ‰ ì‹œë„
        print("\n3ï¸âƒ£  ê²€ìƒ‰ ì‹œë„...")
        search_url = "https://new.land.naver.com/search?sk=ë˜ë¯¸ì•ˆ"
        await page.goto(search_url, wait_until="networkidle")
        await asyncio.sleep(5)

        # 4. ìº¡ì²˜ëœ ë°ì´í„° í™•ì¸
        print("\n" + "=" * 80)
        print("ğŸ“Š ìº¡ì²˜ëœ ë°ì´í„° ìš”ì•½")
        print("=" * 80)

        if captured_data['complexes']:
            print(f"âœ… ë‹¨ì§€ ëª©ë¡: {len(captured_data['complexes'])}ê°œ í•­ëª©")

            # complexes ë°ì´í„° êµ¬ì¡° í™•ì¸
            if isinstance(captured_data['complexes'], dict):
                print(f"   í‚¤: {list(captured_data['complexes'].keys())}")

                # complexListê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'complexList' in captured_data['complexes']:
                    complex_list = captured_data['complexes']['complexList']
                    print(f"   ë‹¨ì§€ ìˆ˜: {len(complex_list)}")

                    if complex_list:
                        print(f"\n   ğŸ“‹ ì²« ë²ˆì§¸ ë‹¨ì§€ ì •ë³´:")
                        first = complex_list[0]
                        for key, value in list(first.items())[:10]:
                            print(f"      {key}: {value}")
        else:
            print("âŒ ë‹¨ì§€ ëª©ë¡ ë°ì´í„° ì—†ìŒ")

        if captured_data['complex_detail']:
            print(f"âœ… ë‹¨ì§€ ìƒì„¸: ìº¡ì²˜ë¨")
        else:
            print("âŒ ë‹¨ì§€ ìƒì„¸ ë°ì´í„° ì—†ìŒ")

        # 5. ìµœì¢… ëŒ€ê¸°
        print("\nâ¸ï¸  ë¸Œë¼ìš°ì €ë¥¼ 60ì´ˆê°„ ì—´ì–´ë‘¡ë‹ˆë‹¤.")
        print("   ì§ì ‘ ë‹¨ì§€ë¥¼ í´ë¦­í•˜ê±°ë‚˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”!")
        await asyncio.sleep(60)

        await browser.close()

        # ì „ì²´ ìº¡ì²˜ ë°ì´í„° ì €ì¥
        with open("all_captured_data.json", "w", encoding="utf-8") as f:
            json.dump(captured_data, f, ensure_ascii=False, indent=2)
        print("\nğŸ’¾ ëª¨ë“  ìº¡ì²˜ ë°ì´í„°: all_captured_data.json")

        print("\nâœ… ì™„ë£Œ!")

        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("ğŸ“‹ ìµœì¢… ìš”ì•½")
        print("=" * 80)

        if any(captured_data.values()):
            print("âœ… ì„±ê³µ! API ì‘ë‹µ ë°ì´í„°ë¥¼ ìº¡ì²˜í–ˆìŠµë‹ˆë‹¤.")
            print("   ì´ì œ ì´ ë°ì´í„° êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í¬ë¡¤ëŸ¬ë¥¼ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ API ì‘ë‹µì„ ìº¡ì²˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("   ë„¤ì´ë²„ ë¶€ë™ì‚°ì˜ ë³´ì•ˆì´ ë§¤ìš° ê°•ë ¥í•©ë‹ˆë‹¤.")
            print("   ê³µê³µ ë°ì´í„° í¬í„¸ API ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    asyncio.run(intercept_and_extract())
