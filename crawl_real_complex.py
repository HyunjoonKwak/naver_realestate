"""
ì‹¤ì œ ë‹¨ì§€ í¬ë¡¤ë§
ë‹¨ì§€ ID: 109208
"""
import asyncio
import json
from playwright.async_api import async_playwright


async def crawl_complex():
    """ì‹¤ì œ ë‹¨ì§€ í¬ë¡¤ë§"""

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        print("=" * 80)
        print("ğŸ¢ ë„¤ì´ë²„ ë¶€ë™ì‚° í¬ë¡¤ë§ - ì‹¤ì œ ë‹¨ì§€")
        print("=" * 80)

        target_url = "https://new.land.naver.com/complexes/109208?ms=37.19921,127.1134283,19&a=APT:PRE:ABYG:JGC&e=RETAIL"

        print(f"\nğŸ“ ë‹¨ì§€ ID: 109208")
        print(f"ğŸ“ URL: {target_url}")

        captured_data = []

        # Routeë¡œ API ì‘ë‹µ ìº¡ì²˜
        async def handle_route(route):
            request = route.request
            req_url = request.url

            # ìš”ì²­ ì§„í–‰
            response = await route.fetch()

            # API ì‘ë‹µ ìº¡ì²˜
            if '/api/' in req_url:
                try:
                    body_bytes = await response.body()
                    body_text = body_bytes.decode('utf-8')

                    # JSON íŒŒì‹±
                    data = json.loads(body_text)

                    print(f"\nâœ… API ìº¡ì²˜!")
                    print(f"   URL: {req_url}")
                    print(f"   Status: {response.status}")

                    captured_data.append({
                        'url': req_url,
                        'status': response.status,
                        'data': data
                    })

                    # íŒŒì¼ ì €ì¥
                    if 'complexes/109208' in req_url:
                        filename = 'complex_109208_detail.json'
                        print(f"   ğŸ“¦ íƒ€ì…: ë‹¨ì§€ ìƒì„¸ ì •ë³´")
                    elif 'article' in req_url.lower():
                        filename = 'complex_109208_articles.json'
                        print(f"   ğŸ“¦ íƒ€ì…: ë§¤ë¬¼ ì •ë³´")
                    elif 'price' in req_url.lower() or 'pyoung' in req_url.lower():
                        filename = 'complex_109208_prices.json'
                        print(f"   ğŸ“¦ íƒ€ì…: ê°€ê²© ì •ë³´")
                    elif 'trade' in req_url.lower() or 'real' in req_url.lower():
                        filename = 'complex_109208_trades.json'
                        print(f"   ğŸ“¦ íƒ€ì…: ì‹¤ê±°ë˜ê°€")
                    else:
                        filename = f"complex_109208_{len(captured_data)}.json"
                        print(f"   ğŸ“¦ íƒ€ì…: ê¸°íƒ€")

                    with open(filename, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    print(f"   ğŸ’¾ ì €ì¥: {filename}")

                    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
                    if isinstance(data, dict):
                        print(f"   ğŸ”‘ í‚¤: {list(data.keys())[:10]}")
                    elif isinstance(data, list):
                        print(f"   ğŸ“Š ë°°ì—´ ê¸¸ì´: {len(data)}")

                except:
                    pass

            # ì‘ë‹µ ì „ë‹¬
            await route.fulfill(response=response)

        await page.route("**/*", handle_route)

        # í˜ì´ì§€ ë¡œë“œ
        print("\nâ³ í˜ì´ì§€ ë¡œë”©...")
        await page.goto(target_url, wait_until="networkidle")
        await asyncio.sleep(5)

        # í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ì¸
        text = await page.evaluate('() => document.body.innerText')
        print(f"\nğŸ“„ í˜ì´ì§€ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì):")
        print(text[:200])

        # ìŠ¤í¬ë¡¤
        print("\nğŸ“œ ìŠ¤í¬ë¡¤ë¡œ ì¶”ê°€ ë°ì´í„° ë¡œë“œ...")
        for i in range(3):
            await page.evaluate('window.scrollBy(0, 500)')
            await asyncio.sleep(1)

        # í´ë¦­ ê°€ëŠ¥í•œ ìš”ì†Œ ì°¾ê¸°
        print("\nğŸ–±ï¸  íƒ­/ë²„íŠ¼ ì°¾ê¸°...")
        clickables = await page.query_selector_all('a, button, [role="tab"]')
        print(f"   ë°œê²¬: {len(clickables)}ê°œ")

        # ì£¼ìš” íƒ­ í´ë¦­
        keywords = ['ë§¤ë¬¼', 'ì‹œì„¸', 'ì‹¤ê±°ë˜', 'ê±°ë˜', 'ë‹¨ì§€ì •ë³´', 'ì •ë³´']
        for elem in clickables:
            try:
                text = await elem.inner_text()
                if text and any(kw in text for kw in keywords):
                    print(f"\n   ğŸ–±ï¸  '{text.strip()}' í´ë¦­...")
                    await elem.click()
                    await asyncio.sleep(3)  # API ì‘ë‹µ ëŒ€ê¸°
            except:
                pass

        # ìŠ¤í¬ë¦°ìƒ·
        await page.screenshot(path="complex_109208_screenshot.png", full_page=True)
        print("\nğŸ“¸ ìŠ¤í¬ë¦°ìƒ·: complex_109208_screenshot.png")

        # ì¶”ê°€ ëŒ€ê¸°
        print("\nâ¸ï¸  ë¸Œë¼ìš°ì €ë¥¼ 60ì´ˆê°„ ì—´ì–´ë‘¡ë‹ˆë‹¤.")
        print("   ìˆ˜ë™ìœ¼ë¡œ íƒ­ì„ í´ë¦­í•˜ê³  ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”!")
        await asyncio.sleep(60)

        await browser.close()

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼")
        print("=" * 80)

        if captured_data:
            print(f"\nâœ… ì„±ê³µ! {len(captured_data)}ê°œì˜ API ì‘ë‹µì„ ìº¡ì²˜í–ˆìŠµë‹ˆë‹¤!")

            # ì „ì²´ ì €ì¥
            with open("complex_109208_all_data.json", "w", encoding='utf-8') as f:
                json.dump(captured_data, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ ì „ì²´ ë°ì´í„°: complex_109208_all_data.json")

            # ê° ë°ì´í„° ë¶„ì„
            print("\nğŸ“‹ ìº¡ì²˜ëœ ë°ì´í„° ë¶„ì„:")
            for i, item in enumerate(captured_data, 1):
                print(f"\n{i}. {item['url'].split('/')[-1].split('?')[0]}")
                data = item['data']

                if isinstance(data, dict):
                    # ë‹¨ì§€ ì •ë³´
                    if 'complexName' in data:
                        print(f"   âœ… ë‹¨ì§€ëª…: {data['complexName']}")
                        print(f"   âœ… ì£¼ì†Œ: {data.get('address', 'N/A')}")
                        print(f"   âœ… ì„¸ëŒ€ìˆ˜: {data.get('totalHouseholdCount', 'N/A')}")
                        print(f"   âœ… ì¤€ê³µ: {data.get('useApproveYmd', 'N/A')}")

                    # ë§¤ë¬¼
                    if 'articleList' in data:
                        articles = data['articleList']
                        print(f"   âœ… ë§¤ë¬¼: {len(articles)}ê±´")
                        for j, art in enumerate(articles[:3], 1):
                            print(f"      {j}. {art.get('dealOrWarrantPrc', 'N/A')} / "
                                  f"{art.get('area1', 'N/A')}ã¡ / {art.get('floorInfo', 'N/A')}")

                    # ì‹¤ê±°ë˜ê°€
                    if 'list' in data and isinstance(data['list'], list):
                        trades = data['list']
                        print(f"   âœ… ì‹¤ê±°ë˜: {len(trades)}ê±´")
                        for j, t in enumerate(trades[:3], 1):
                            print(f"      {j}. {t.get('dealAmount', t.get('price', 'N/A'))} / "
                                  f"{t.get('dealDate', 'N/A')}")

        else:
            print("\nâŒ API ì‘ë‹µì„ ìº¡ì²˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print("   í˜ì´ì§€ê°€ 404ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

        print("\nâœ… í¬ë¡¤ë§ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(crawl_complex())
